#!/usr/bin/env node

/**
 * Bolt.diy Integration Test
 * 
 * Simulates how Bolt.diy would interact with the MCP server
 */

import WebSocket from 'ws';
import fetch from 'node-fetch';

const MCP_WS_URL = process.env.MCP_SERVER_URL || 'ws://localhost:8080/ws';
const MCP_HTTP_URL = MCP_WS_URL.replace('ws://', 'http://').replace('/ws', '');

class BoltMCPIntegration {
  constructor() {
    this.ws = null;
    this.requestId = 0;
    this.pendingRequests = new Map();
  }

  // Simulate Bolt.diy connecting to MCP server
  async connect() {
    return new Promise((resolve, reject) => {
      console.log('üîó Bolt.diy: Connecting to MCP server...');
      
      this.ws = new WebSocket(MCP_WS_URL);

      this.ws.on('open', () => {
        console.log('‚úÖ Bolt.diy: Connected to MCP server');
        resolve();
      });

      this.ws.on('message', (data) => {
        const message = JSON.parse(data.toString());
        this.handleMessage(message);
      });

      this.ws.on('error', (error) => {
        console.error('‚ùå Bolt.diy: Connection error:', error);
        reject(error);
      });
    });
  }

  handleMessage(message) {
    // Handle JSON-RPC responses
    if (message.jsonrpc === '2.0' && message.id !== undefined) {
      const pending = this.pendingRequests.get(message.id);
      if (pending) {
        this.pendingRequests.delete(message.id);
        if (message.error) {
          pending.reject(new Error(message.error.message));
        } else {
          pending.resolve(message.result);
        }
      }
    }
  }

  // Send MCP request and wait for response
  async sendMCPRequest(method, params) {
    return new Promise((resolve, reject) => {
      const id = ++this.requestId;
      const request = {
        jsonrpc: '2.0',
        id,
        method,
        params
      };

      this.pendingRequests.set(id, { resolve, reject });
      this.ws.send(JSON.stringify(request));

      // Timeout after 10 seconds
      setTimeout(() => {
        if (this.pendingRequests.has(id)) {
          this.pendingRequests.delete(id);
          reject(new Error('Request timeout'));
        }
      }, 10000);
    });
  }

  // Simulate Bolt.diy workflow
  async runBoltWorkflow() {
    console.log('\nüöÄ Starting Bolt.diy workflow simulation...\n');

    try {
      // Step 1: Discover available tools
      console.log('üìã Step 1: Discovering MCP tools...');
      const tools = await this.sendMCPRequest('tools/list', {});
      console.log(`Found ${tools.tools.length} tools:`);
      tools.tools.forEach(tool => {
        console.log(`  - ${tool.name}: ${tool.description}`);
      });

      // Step 2: User requests to see data stores
      console.log('\nüìä Step 2: User asks to list data stores...');
      const datastores = await this.sendMCPRequest('tools/call', {
        name: 'xdp_list_datastores',
        arguments: {
          page: 0,
          size: 5
        }
      });
      console.log('Data stores retrieved successfully');

      // Step 3: User wants to explore Trino catalogs
      console.log('\nüóÑÔ∏è Step 3: User wants to explore Trino catalogs...');
      // This would normally use a real dataplane ID
      const mockDataplaneId = 'test-dataplane';
      
      try {
        const catalogs = await this.sendMCPRequest('tools/call', {
          name: 'trino_list_catalogs',
          arguments: {
            dataplane: mockDataplaneId
          }
        });
        console.log('Trino catalogs retrieved');
      } catch (error) {
        console.log('Note: Trino catalog listing requires valid dataplane ID');
      }

      // Step 4: Generate code based on schema (simulated)
      console.log('\nüíª Step 4: Generating PySpark code for data deduplication...');
      const generatedCode = this.generatePySparkCode('snowflake_table', 'deduplicated_table');
      console.log('Generated code:');
      console.log('```python');
      console.log(generatedCode);
      console.log('```');

      // Step 5: Test HTTP fallback
      console.log('\nüîÑ Step 5: Testing HTTP fallback mechanism...');
      const healthResponse = await fetch(`${MCP_HTTP_URL}/health`);
      const health = await healthResponse.json();
      console.log('Health check via HTTP:', health);

      console.log('\n‚úÖ Bolt.diy workflow simulation completed successfully!');

    } catch (error) {
      console.error('‚ùå Workflow error:', error);
    }
  }

  // Simulate code generation that Bolt.diy would do
  generatePySparkCode(sourceTable, targetTable) {
    return `from pyspark.sql import SparkSession
from pyspark.sql.functions import row_number
from pyspark.sql.window import Window

# Initialize Spark session with Snowflake connector
spark = SparkSession.builder \\
    .appName("SnowflakeDeduplication") \\
    .config("spark.jars", "/path/to/snowflake-spark-connector.jar") \\
    .getOrCreate()

# Snowflake connection options
sf_options = {
    "sfURL": "your-account.snowflakecomputing.com",
    "sfUser": "username",
    "sfPassword": "password",
    "sfDatabase": "database",
    "sfSchema": "schema",
    "sfWarehouse": "warehouse"
}

# Read source table from Snowflake
df_source = spark.read \\
    .format("snowflake") \\
    .options(**sf_options) \\
    .option("dbtable", "${sourceTable}") \\
    .load()

# Define window specification for deduplication
# Adjust partition columns based on your business logic
window_spec = Window.partitionBy("id").orderBy("updated_at")

# Add row number and filter to keep only the latest record
df_deduplicated = df_source \\
    .withColumn("row_num", row_number().over(window_spec)) \\
    .filter("row_num = 1") \\
    .drop("row_num")

# Write deduplicated data back to Snowflake
df_deduplicated.write \\
    .format("snowflake") \\
    .options(**sf_options) \\
    .option("dbtable", "${targetTable}") \\
    .mode("overwrite") \\
    .save()

print(f"Deduplication complete. Records written to ${targetTable}")
spark.stop()`;
  }

  // Test connection resilience
  async testReconnection() {
    console.log('\nüîÑ Testing connection resilience...');
    
    // Simulate connection drop
    console.log('Simulating connection drop...');
    this.ws.close();
    
    await new Promise(resolve => setTimeout(resolve, 2000));
    
    console.log('Attempting reconnection...');
    await this.connect();
    
    // Test if we can still make requests
    const tools = await this.sendMCPRequest('tools/list', {});
    console.log('‚úÖ Reconnection successful, retrieved', tools.tools.length, 'tools');
  }

  disconnect() {
    if (this.ws) {
      this.ws.close();
    }
  }
}

// Performance test
async function performanceTest() {
  console.log('\n‚ö° Running performance test...');
  const client = new BoltMCPIntegration();
  await client.connect();

  const startTime = Date.now();
  const requests = 50;

  const promises = [];
  for (let i = 0; i < requests; i++) {
    promises.push(
      client.sendMCPRequest('tools/list', {})
        .catch(err => console.error(`Request ${i} failed:`, err))
    );
  }

  await Promise.all(promises);
  const duration = Date.now() - startTime;

  console.log(`Completed ${requests} requests in ${duration}ms`);
  console.log(`Average: ${(duration / requests).toFixed(2)}ms per request`);
  console.log(`Throughput: ${(requests / (duration / 1000)).toFixed(2)} req/s`);

  client.disconnect();
}

// Main execution
async function main() {
  const client = new BoltMCPIntegration();

  try {
    await client.connect();
    
    // Run the full workflow
    await client.runBoltWorkflow();
    
    // Test reconnection
    await client.testReconnection();
    
    // Optional: Run performance test
    if (process.argv.includes('--perf')) {
      await performanceTest();
    }

  } catch (error) {
    console.error('‚ùå Test failed:', error);
    process.exit(1);
  } finally {
    client.disconnect();
  }

  console.log('\nüéâ All integration tests completed!');
  process.exit(0);
}

main();